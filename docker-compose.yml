version: "3.9"
services:
  ##########################################
  ##  Network Load Balancer for Services  ##
  ##########################################
  proxy:
    image: 'jc21/nginx-proxy-manager:latest'
    restart: unless-stopped
    ports:
      # These ports are in format <host-port>:<container-port>
      - '80:80' # Public HTTP Port
      - '443:443' # Public HTTPS Port
      - '81:81' # Admin Web Port
      # Add any other Stream port you want to expose
      - '21:21' # FTP
    environment:
      # Mysql/Maria connection parameters:
      DB_MYSQL_HOST: "db"
      DB_MYSQL_PORT: 3306
      DB_MYSQL_USER: "npm"
      DB_MYSQL_PASSWORD: "npm"
      DB_MYSQL_NAME: "npm"
      # Uncomment this if IPv6 is not enabled on your host
      # DISABLE_IPV6: 'true'
    volumes:
      - ./data:/data
      - ./letsencrypt:/etc/letsencrypt
    depends_on:
      - db
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

  db:
    image: 'jc21/mariadb-aria:latest'
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: 'npm'
      MYSQL_DATABASE: 'npm'
      MYSQL_USER: 'npm'
      MYSQL_PASSWORD: 'npm'
    volumes:
      - mysql_data1:/var/lib/mysql


  ##########################
  ##  Network Controller  ##
  ##########################

  unifi:
    image: linuxserver/unifi-controller
    restart: always
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      - MEM_LIMIT=4096 #optional
      - MEM_STARTUP=1024 #optional
    volumes:
      - unifi:/config
    ports:
      - "3478:3478/udp"
      - "10001:10001/udp"
      - "8080:8080"
      - "8443:8443"
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

  ####################
  ##  DevOps Stack  ##
  ####################

  jenkins:
    image: jenkins/jenkins:lts
    volumes:
      - jenkins:/var/jenkins_home
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

  heimdall:
    image: linuxserver/heimdall
    privileged: true
    ports:
      - "3443:443"
      - "3081:80"
    volumes:
      - heimdall:/config

  memcached:
    image: 'bitnami/memcached:latest'
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
    deploy:
      replicas: 3

  cache:
    image: redis
    restart: always
    ports:
      - '6379:6379'
    labels:
      - "com.centurylinklabs.watchtower.enable=true"

  watchtower:
    image: containrrr/watchtower
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /etc/timezone:/etc/timezone:ro
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_LABEL_ENABLE=true
      - WATCHTOWER_INCLUDE_RESTARTING=true
    labels:
      - "com.centurylinklabs.watchtower.enable=true"


  ################
  ##  Websites  ##
  ################

  sinlessgames:
    image: sinless777/gateway:1.1.3
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
    deploy:
      replicas: 3


  #########################
  ##  Tyler's WordPress  ##
  #########################
  mysql:
    image: mysql:8.0
    volumes:
      - mysql_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress

  phpmyadmin:
    image: phpmyadmin/phpmyadmin
    depends_on:
      - mysql
    environment:
      PMA_HOST: mysql
      PMA_PORT: 3306
      PMA_ARBITRARY: 1
    restart: always
    ports:
      - '8183:80'

  iconiclastart:
    image: wordpress:latest
    restart: always
    environment:
      WORDPRESS_DB_HOST: mysql:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress:/var/www/html
    deploy:
      replicas: 3

  #################################
  ###                           ###
  ###   Mobius Infernium | MC   ###
  ###                           ###
  #################################

  mobius:
    image: sinless777/mobius_gateway:latest
    labels:
      - "com.centurylinklabs.watchtower.enable=true"
    deploy:
      replicas: 3

  #################################
  ###                           ###
  ###       Helix Ai Stack      ###
  ###                           ###
  #################################

  ###   CONSUL   ###

  consul-server1:
    image: hashicorp/consul:1.11.2
    container_name: consul-server1
    hostname: consul-server1
    networks:
      - helix-ai
    depends_on:
      - vault-server
    restart: always
    volumes:
      - /home/sinless777/services/helix/consul/server1.json:/consul/config/server1.json
      - /home/sinless777/services/helix/certs/:/consul/config/certs/:ro
      - /home/sinless777/services/helix/consul/acls/:/consul/config/acls/
    ports:
      - "8500:8500"
      - "8600:8600/tcp"
      - "8600:8600/udp"
    command: "agent -bootstrap-expect=3"

  consul-server2:
    image: hashicorp/consul:1.11.2
    container_name: consul-server2
    hostname: consul-server2
    networks:
      - helix-ai
    depends_on:
      - vault-server
    restart: always
    volumes:
      - /home/sinless777/services/helix/consul/server2.json:/consul/config/server2.json
      - /home/sinless777/services/helix/certs/:/consul/config/certs/:ro
      - /home/sinless777/services/helix/consul/acls/:/consul/config/acls/
    command: "agent -bootstrap-expect=3"

  consul-server3:
    image: hashicorp/consul:1.11.2
    container_name: consul-server3
    hostname: consul-server3
    networks:
      - helix-ai
    depends_on:
      - vault-server
    restart: always
    volumes:
      - /home/sinless777/services/helix/consul/server3.json:/consul/config/server3.json
      - /home/sinless777/services/helix/certs/:/consul/config/certs/:ro
      - /home/sinless777/services/helix/consul/acls/:/consul/config/acls/
    command: "agent -bootstrap-expect=3"

  consul-client:
    image: hashicorp/consul:1.11.2
    container_name: consul-client
    hostname: consul-client
    restart: always
    networks:
      - helix-ai
    volumes:
      - /home/sinless777/services/helix/consul/client.json:/consul/config/client.json
      - /home/sinless777/services/helix/certs/:/consul/config/certs/:ro
      - /home/sinless777/services/helix/tokens/:/consul/config/tokens/
    command: "agent"

  ###   WEAVESCOPE   ###

  weavescope:
    image: weaveworks/scope:latest
    container_name: weavescope
    hostname: weavescope
    pid: "host"
    privileged: true
    networks:
      - helix-ai
    ports:
      - "4040:4040"
    labels:
      - "works.weave.role=system"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:rw"
    command:
      - "--probe.docker=true"
      - "--weave=false"

  ###   BEATS SYSTEM   ###

  # How to Tune Elastic Beats Performance: A Practical Example with Batch Size, Worker Count, and More
  # https://www.elastic.co/blog/how-to-tune-elastic-beats-performance-a-practical-example-with-batch-size-worker-count-and-more?blade=tw&hulk=social
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.8.2
    # https://github.com/docker/swarmkit/issues/1951
    hostname: filebeat
    # Need to override user so we can access the log files, and docker.sock
    user: root
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    configs:
      - source: fb_config
        target: /usr/share/filebeat/filebeat.yml
    volumes:
      - /home/sinless777/services/helix/filebeat:/usr/share/filebeat/data
      - /var/run/docker.sock:/var/run/docker.sock
      # This is needed for filebeat to load container log path as specified in filebeat.yml
      - /var/lib/docker/containers/:/var/lib/docker/containers/:ro

      # # This is needed for filebeat to load jenkins build log path as specified in filebeat.yml
      # - /var/lib/docker/volumes/jenkins_home/_data/jobs/:/var/lib/docker/volumes/jenkins_home/_data/jobs/:ro

      # This is needed for filebeat to load logs for system and auth modules
      - /var/log/:/var/log/:ro
      # This is needed for filebeat to load logs for auditd module. you might have to install audit system
      # on ubuntu first (sudo apt-get install -y auditd audispd-plugins)
      - /var/log/audit/:/var/log/audit/:ro
    environment:
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - KIBANA_HOST=http://kibana:5601
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=Shellshocker93!
    # disable strict permission checks
    command: [ "--strict.perms=false" ]

  metricbeat:
    image: docker.elastic.co/beats/metricbeat:8.8.2
    # https://github.com/docker/swarmkit/issues/1951
    hostname: metricbeat
    user: root
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    configs:
      - source: mb_config
        target: /usr/share/metricbeat/metricbeat.yml
    volumes:
      - /proc:/hostfs/proc:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      - /:/hostfs:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/sinless777/services/helix/metricbeat:/usr/share/metricbeat/data
    environment:
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - KIBANA_HOST=http://kibana:5601
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=Shellshocker93!
    # disable strict permission checks
    command: [ "--strict.perms=false", "-system.hostfs=/hostfs" ]

  packetbeat:
    image: docker.elastic.co/beats/packetbeat:8.8.2
    # https://github.com/docker/swarmkit/issues/1951
    hostname: packetbeat
    user: root
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    configs:
      - source: pb_config
        target: /usr/share/packetbeat/packetbeat.yml
    volumes:
      - /home/sinless777/services/helix/packetbeat:/usr/share/packetbeat/data
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - KIBANA_HOST=http://kibana:5601
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=Shellshocker93!
      # Eagerly waiting for Docker 19.06 release which will bring --privileged flag to Docker
      # Swarm Mode https://github.com/moby/moby/issues/24862#issuecomment-451594187
      # support for capabilities https://github.com/moby/moby/pull/38380
    cap_add:
      - NET_RAW
      - NET_ADMIN
    command: [ "--strict.perms=false" ]

  auditbeat:
    image: docker.elastic.co/beats/auditbeat:8.8.2
    # https://github.com/docker/swarmkit/issues/1951
    hostname: auditbeat
    # Need to override user so we can access the log files, and docker.sock
    user: root
    # https://www.elastic.co/guide/en/beats/auditbeat/current/running-on-docker.html#_special_requirements
    # PID and CAP_ADD options are ignored as they are Not yet available in swarm mode at the moment.
    # Eagerly waiting for Docker 19.06 release which will bring --privileged flag to Docker
    # Swarm Mode https://github.com/moby/moby/issues/24862#issuecomment-451594187
    # support for capabilities https://github.com/moby/moby/pull/38380
    pid: host
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    cap_add:
      - AUDIT_CONTROL
      - AUDIT_READ
    configs:
      - source: ab_config
        target: /usr/share/auditbeat/auditbeat.yml
    volumes:
      - /home/sinless777/services/helix/auditbeat/data:/usr/share/auditbeat/data
      - /var/log:/var/log:ro
    environment:
      - ELASTICSEARCH_HOST=http://elasticsearch:9200
      - KIBANA_HOST=http://kibana:5601
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=Shellshocker93!
    command: [ "--strict.perms=false" ]

  ###   VAULT   ###

  vault-server:
    image: hashicorp/vault:1.9.6
    container_name: vault-server
    hostname: vault-server
    restart: always
    networks:
      - helix-ai
    ports:
      - "8200:8200"
    environment:
      VAULT_ADDR: "http://vault-server:8200"
      VAULT_API_ADDR: "http://vault-server:8200"
      VAULT_DEV_ROOT_TOKEN_ID: "vault-plaintext-root-token"
      CONSUL_HTTP_ADDR: "consul-server1:8500"
      CONSUL_HTTP_TOKEN: "e95b599e-166e-7d80-08ad-aee76e7ddf19"
    cap_add:
      - IPC_LOCK
    volumes:
      - /home/sinless777/services/helix/vault/policies:/vault/policies
      - /home/sinless777/services/helix/vault/vault.hcl:/etc/vault.hcl
      - /home/sinless777/services/helix/vault/data:/mnt/vault/data
    command: "server -config=/etc/vault.hcl"
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8200 || exit 1
      interval: 10s
      retries: 12
      start_period: 10s
      timeout: 10s

  vdb:
    image: mysql:8.0
    volumes:
      - mysql_data2:/var/lib/mysql
    restart: always
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: Shellshocker93
      MYSQL_DATABASE: vault
      MYSQL_USER: vault
      MYSQL_PASSWORD: vault

  ###   ELK-STACK   ###

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.2
    container_name: elasticsearch
    restart: always
    ports:
      - "9200:9200"
    environment:
      node.name: es-master ## node name needs to be unique, so setting it in env vars
      ELASTIC_PASSWORD: Shellshocker93!
      cluster.name: "elasticsearch"
      network.host: 0.0.0.0
      xpack.security.enabled: true
      xpack.monitoring.collection.enabled: true
      xpack.security.audit.enabled: true
      xpack.license.self_generated.type: trial
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      discovery.type: single-node
    volumes:
      - /home/sinless777/services/helix/elasticsearch/logs:/usr/share/elasticsearch/logs/"elasticsearch".log
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      retries: 300
      interval: 1s
      test: ["CMD-SHELL", "curl -u elastic:Shellshocker93! -s http://localhost:9200/_cat/health?h=status | grep -q green"]

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.2
    container_name: logstash
    links:
      - elasticsearch:elasticsearch
      - zoo1:zoo1
    depends_on:
      elasticsearch:
        condition: service_healthy
      zoo1:
        condition: service_healthy
    environment:
      - XPACK_MONITORING_ELASTICSEARCH_URL=http://elasticsearch:9200
      - XPACK_MONITORING_ELASTICSEARCH_USERNAME=elastic
      - XPACK_MONITORING_ELASTICSEARCH_PASSWORD=Shellshocker93!
      - "LS_HEAP_SIZE=-Xms512m -Xmx512m"

    volumes:
      - /home/sinless777/services/helix/logstash/config:/usr/share/logstash/config
      - /home/sinless777/services/helix/logstash/pipelines:/usr/share/logstash/pipeline/  ## this is the pipeline config location
      - /home/sinless777/services/helix/logstash/logs:/mnt/logs  ## this is the logs volume path, just to stick with the original
      - /home/sinless777/services/helix/logstash/data:/usr/share/logstash/data
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    command: logstash -f /usr/share/logstash/pipeline/logstash.conf

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.2
    container_name: kibana
    hostname: kibana
    networks:
      - helix-ai
    ports:
      - "5601:5601"
    volumes:
      - /home/sinless777/services/helix/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: curl --write-out 'HTTP %{http_code}' --fail --silent --output /dev/null http://localhost:8200/
      retries: 300
      interval: 1s

  apm-server:
    image: docker.elastic.co/apm/apm-server:8.8.2
    container_name: apm-server
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    hostname: apm-server
    command: >
      --strict.perms=false -e
      -E apm-server.rum.enabled=true
      -E setup.kibana.host=http://kibana:5601
      -E setup.kibana.username=elastic
      -E setup.kibana.password=Shellshocker93!
      -E setup.template.settings.index.number_of_replicas=0
      -E apm-server.kibana.enabled=true
      -E apm-server.kibana.host=http://kibana:5601
      -E apm-server.kibana.username=elastic
      -E apm-server.kibana.password=Shellshocker93!
      -E output.elasticsearch.hosts=["http://elasticsearch:9200"]
      -E output.elasticsearch.username=elastic
      -E output.elasticsearch.password=Shellshocker93!
      -E xpack.monitoring.enabled=true





  httpd:
    image: httpd:latest
    networks:
      - helix-ai
    depends_on:
      - logstash
    ports:
      - 4000:80
    logging:
      driver: gelf
      options:
        # Use udp://host.docker.internal:12201 when you are using Docker Desktop for Mac
        # docs: https://docs.docker.com/docker-for-mac/networking/#i-want-to-connect-from-a-container-to-a-service-on-the-host
        # issue: https://github.com/lvthillo/docker-elk/issues/1
        gelf-address: "udp://localhost:12201"

  ###   KAFKA   ###

  #######################
  ###   Kafka Stack   ###   WORKING
  #######################
  zoo1:
    image: confluentinc/cp-zookeeper:latest
    container_name: "zoo1"
    hostname: "zoo1"
    restart: always
    networks:
      - helix-ai
    volumes:
      - /home/sinless777/services/helix/zookeeper/z1/data:/var/lib/zookeeper/data
      - /home/sinless777/services/helix/zookeeper/z1/logs:/var/lib/zookeeper/logs
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "22181:2181"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:22181" ]
      interval: 10s
      timeout: 10s
      retries: 5

  zoo2:
    image: confluentinc/cp-zookeeper:latest
    container_name: "zoo2"
    hostname: "zoo2"
    restart: always
    networks:
      - helix-ai
    volumes:
      - /home/sinless777/services/helix/zookeeper/z2/data:/var/lib/zookeeper/data
      - /home/sinless777/services/helix/zookeeper/z2/logs:/var/lib/zookeeper/logs
    environment:
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_CLIENT_PORT: 2182
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "22182:2181"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:22182" ]
      interval: 10s
      timeout: 10s
      retries: 5

  zoo3:
    image: confluentinc/cp-zookeeper:latest
    container_name: "zoo3"
    hostname: "zoo3"
    restart: always
    networks:
      - helix-ai
    volumes:
      - /home/sinless777/services/helix/zookeeper/z3/data:/var/lib/zookeeper/data
      - /home/sinless777/services/helix/zookeeper/z3/logs:/var/lib/zookeeper/logs
    environment:
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_CLIENT_PORT: 2183
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "22183:2181"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:22183" ]
      interval: 10s
      timeout: 10s
      retries: 5

  kafka1:
    image: confluentinc/cp-kafka:latest
    container_name: "kafka1"
    hostname: "kafka1"
    restart: always
    depends_on:
      zoo1:
        condition: service_healthy
      zoo2:
        condition: service_healthy
      zoo3:
        condition: service_healthy
    networks:
      - helix-ai
    volumes:
      - /home/sinless777/services/helix/kafka/kafka1:/kafka/data
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2181,zoo3:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
      KAFKA_LISTENERS: PLAINTEXT://


  zoo-navigator:
    container_name: zoo-navigator
    image: elkozmon/zoonavigator
    networks:
      - helix-ai
    ports:
      - 9000:9000
    environment:
      CONNECTION_ZOO1_CONN: zoo1:2181
      CONNECTION_ZOO1_NAME: zoo1
      HTTP_PORT: 9000
      ZK_CLIENT_CNXN_SOCKET: 'org.apache.zookeeper.ClientCnxnSocketNIO'
    depends_on:
      zoo1:
        condition: service_healthy
      zoo2:
        condition: service_healthy
      zoo3:
        condition: service_healthy


  ###   MONITORING   ###

  grafana:
    image: grafana/grafana:7.5.3
    container_name: grafana
    restart: always
    networks:
      - helix-ai
    volumes:
      - /home/sinless777/services/helix/grafana/grafana.ini:/etc/grafana/grafana.ini
      - /home/sinless777/services/helix/grafana/provisioning/:/etc/grafana/provisioning
      - /home/sinless777/services/helix/grafana/dashboards/:/var/lib/grafana/dashboards
    ports:
      - "3000:3000"

  prometheus:
    image: prom/prometheus:v2.26.0
    container_name: prometheus
    restart: always
    networks:
      - helix-ai
    volumes:
      - /home/sinless777/services/helix/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - 9090:9090
    command: --web.enable-lifecycle  --config.file=/etc/prometheus/prometheus.yml

  node-exporter:
    image: prom/node-exporter
    container_name: node-exporter
    restart: always
    networks:
      - helix-ai
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - --collector.filesystem.ignored-mount-points
      - "^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)"
    ports:
      - 9100:9100

  ###   SONAR   ###

  sonarqube:
    image: sonarqube:community
    container_name: sonarqube
    hostname: sonarqube
    networks:
      - helix-ai
      - default
    ports:
      - "9900:9000"
    environment:
      - SONARQUBE_JDBC_USERNAME=sonar
      - SONARQUBE_JDBC_PASSWORD=sonar
      - SONARQUBE_JDBC_URL=jdbc:postgresql://db:5432/sonar
    depends_on:
      - pg

  pg:
    image: postgres:13.2
    container_name: db
    hostname: db
    networks:
      - helix-ai
    ports:
      - "5432:5432"
    volumes:
      - /home/sinless777/services/helix/db:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=sonar
      - POSTGRES_PASSWORD=sonar

###############
##  Volumes  ##
###############

volumes:
  jenkins:
    driver: local
    driver_opts:
      type: none
      device: /home/sinless777/services/jenkins
      o: bind

  unifi:
    driver: local
    driver_opts:
      type: none
      device: /home/sinless777/services/unifi
      o: bind

  heimdall:
    driver: local
    driver_opts:
      type: none
      device: /home/sinless777/services/heimdall
      o: bind

  mobius:
    driver: local
    driver_opts:
      type: none
      device: /home/sinless777/services/mobius
      o: bind

  wordpress:
    driver: local
    driver_opts:
      type: none
      device: /home/sinless777/services/iconiclast-art
      o: bind

  mysql_data:
    driver: local
    driver_opts:
      type: none
      device: /home/sinless777/services/iconiclast-art/mysql
      o: bind

  mysql_data1:
    driver: local
    driver_opts:
      type: none
      device: /home/sinless777/services/mysql/nginx-proxy
      o: bind

  mysql_data2:
    driver: local
    driver_opts:
      type: none
      device: /home/sinless777/services/helix/mysql
      o: bind


################
##  Networks  ##
################

networks:
  default:
    driver: bridge

  helix-ai:
    driver: bridge

###############
##  Configs  ##
###############
configs:
  fb_config:
    file: /home/sinless777/services/helix/beats/filebeat/config/filebeat.yml
  mb_config:
    file: /home/sinless777/services/helix/beats/metricbeat/config/metricbeat.yml
  ab_config:
    file: /home/sinless777/services/helix/beats/auditbeat/config/auditbeat.yml
  pb_config:
    file: /home/sinless777/services/helix/beats/packetbeat/config/packetbeat.yml
